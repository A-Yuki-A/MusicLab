import streamlit as st
from pydub import AudioSegment
import numpy as np
import matplotlib.pyplot as plt
import librosa
import tempfile
import soundfile as sf

# â”€â”€ ffmpeg/ffprobe ã®ãƒ‘ã‚¹æŒ‡å®š â”€â”€
AudioSegment.converter = "/usr/bin/ffmpeg"
AudioSegment.ffprobe   = "/usr/bin/ffprobe"

def load_mp3(uploaded_file):
    """
    Load MP3 via temp file and return normalized numpy array and sampling rate.
    """
    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name
    audio = AudioSegment.from_file(tmp_path, format="mp3")
    sr = audio.frame_rate
    data = np.array(audio.get_array_of_samples(), dtype=np.float32)
    if audio.channels == 2:
        # ã‚¹ãƒ†ãƒ¬ã‚ªã‚’ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
        data = data.reshape((-1, 2)).mean(axis=1)
    # -1ã€œ1 ã®ç¯„å›²ã«æ­£è¦åŒ–
    data /= np.abs(data).max()
    return data, sr

st.title("ğŸ§ MP3 Resampler & Quantizer")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded = st.file_uploader("Upload MP3 file", type="mp3")
if not uploaded:
    st.info("Please upload an MP3 file to continue.")
    st.stop()

# ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªèª­ã¿è¾¼ã¿
data, orig_sr = load_mp3(uploaded)

# â”€â”€ Settings â”€â”€
st.write("### Settings")

# æ¨™æœ¬åŒ–å‘¨æ³¢æ•°ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
target_sr = st.slider("Sampling Rate (Hz)", 8000, 48000, orig_sr, step=1000)
st.caption("ğŸ”Š æ¨™æœ¬åŒ–å‘¨æ³¢æ•°ï¼ˆSampling Rateï¼‰ã‚’ä¸‹ã’ã‚‹ã¨ã€é«˜ã„éŸ³ãŒå¤±ã‚ã‚Œã¦éŸ³ãŒã“ã‚‚ã£ãŸæ„Ÿã˜ã«ãªã‚Šã¾ã™ã€‚")

# é‡å­åŒ–ãƒ“ãƒƒãƒˆæ•°ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
bit_depth = st.slider("Quantization Bits", 8, 24, 16, step=1)
st.caption("ğŸ”‰ é‡å­åŒ–ãƒ“ãƒƒãƒˆæ•°ï¼ˆBit Depthï¼‰ã‚’ä¸‹ã’ã‚‹ã¨ã€éŸ³ã®æ»‘ã‚‰ã‹ã•ãŒå¤±ã‚ã‚Œã€ãƒã‚¤ã‚ºãŒå¢—ãˆãŸã‚ˆã†ã«èã“ãˆã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚")

st.write(f"Original SR: {orig_sr} Hz â†’ Target SR: {target_sr} Hz | Quantization: {bit_depth}-bit")

# ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨é‡å­åŒ–
data_rs = librosa.resample(data, orig_sr=orig_sr, target_sr=target_sr)
max_int = 2**(bit_depth - 1) - 1
quantized = np.round(data_rs * max_int) / max_int

# â”€â”€ Waveform Comparison â”€â”€
st.write("### Waveform Comparison")
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(8, 9), constrained_layout=True)

# ã™ã¹ã¦åŒã˜è»¸ç¯„å›²ã«å›ºå®š
max_time = len(data) / orig_sr
ax1.set_xlim(0, max_time)
ax2.set_xlim(0, max_time)
ax1.set_ylim(-1, 1)
ax2.set_ylim(-1, 1)

# 1. å…ƒã®æ³¢å½¢
t_orig = np.linspace(0, max_time, num=len(data))
ax1.plot(t_orig, data)
ax1.set_title("Original Waveform")
ax1.set_xlabel("Time (s)")
ax1.set_ylabel("Amplitude")

# 2. å‡¦ç†å¾Œã®æ³¢å½¢
proc_len = min(len(quantized), int(max_time * target_sr))
t_proc = np.linspace(0, max_time, num=proc_len)
ax2.plot(t_proc, quantized[:proc_len])
ax2.set_title(f"Processed Waveform ({target_sr} Hz, {bit_depth}-bit)")
ax2.set_xlabel("Time (s)")
ax2.set_ylabel("Amplitude")

# 3. æœ€åˆã®20msã‚’æ‹¡å¤§
zoom_duration = 0.02  # 20 ms
zoom_len = int(target_sr * zoom_duration)
time_zoom = np.linspace(0, zoom_duration, num=zoom_len)
zoom_resampled = data_rs[:zoom_len]
zoom_quant = quantized[:zoom_len]
ax3.plot(time_zoom, zoom_resampled, label="Resampled", linestyle='-')
ax3.step(time_zoom, zoom_quant, where='mid', label="Quantized", linewidth=1.0)
ax3.plot(time_zoom, zoom_quant, marker='o', linestyle='None', label="Quantized Samples")
ax3.set_title("Zoomed Waveform (First 20 ms)")
ax3.set_xlabel("Time (s)")
ax3.set_ylabel("Amplitude")
ax3.legend()

st.pyplot(fig, use_container_width=False)

# â”€â”€ WAV ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãå‡ºã— & å†ç”Ÿ â”€â”€
subtype_map = {8: 'PCM_U8', 16: 'PCM_16', 24: 'PCM_24'}
selected_subtype = subtype_map.get(bit_depth, 'PCM_16')
with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as out:
    sf.write(out.name, quantized, target_sr, subtype=selected_subtype)
    st.audio(out.name, format="audio/wav")
